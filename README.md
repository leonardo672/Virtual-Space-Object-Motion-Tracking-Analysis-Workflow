# Virtual Space Object Motion Tracking & Analysis Workflow

<p>In the intricate process of tracking and analyzing the motion of a space object, specifically a satellite in our hypothetical scenario, the journey begins with precisely locating the satellite using YOLOv5 on video frames. This real-time detection provides the foundation for a comprehensive spatial understanding. The next step is to transition into a 3D visualization of the satellite’s motion and its proximity to nearby sensors, giving a detailed spatial context that informs subsequent analyses. The process then involves creating a video from 3D images that captures the satellite's movement, offering a fluid and continuous depiction of its trajectory. This is crucial for both real-time monitoring and post-event analysis. As the satellite’s dynamics are observed, real-time spatial analysis examines the interactions between the satellite and observers within 3D space. Dynamic visualization of the satellite’s coordinates and those of the observers provides deeper insights into these relationships. Triangulation is then used to determine the precise position of the satellite, which is critical for visualizing its coordinate trajectory over time based on the triangulation results. The visual analysis is enhanced by dynamic 3D visualization, capturing the satellite’s trajectory and the interaction with sensors post-triangulation. A timelapse video is created to provide a condensed view of the satellite’s journey. To ensure accuracy, a virtual evaluator assesses the precision of the triangulation coordinates, followed by a thorough check and visualization of the 3D coordinates. If discrepancies are found, a correction process refines the triangulated coordinates, which are then re-verified and visualized to confirm accuracy. The final 3D modeling of the satellite’s motion post-correction ensures that the refined data accurately reflects the satellite’s true path. The last step involves converting the corrected 3D model into a video, followed by an evaluation of the performance of the sensors used throughout the process, ensuring optimal functionality from start to finish. </p> 

![image](https://github.com/user-attachments/assets/64d766fb-3061-4f99-b417-ce3def631d1b)

![image](https://github.com/user-attachments/assets/8b4e3cf3-af2e-4ef4-8cb2-ac101fc8e2cf)

![image](https://github.com/user-attachments/assets/6feb4d2d-2d7e-44c3-9ede-c6db091678f0)

![image](https://github.com/user-attachments/assets/b5e15b10-52b1-49cf-a848-55cc1bcd83c9)

![image](https://github.com/user-attachments/assets/05b74a59-799c-4219-9423-01ab037860d8)










